---
title: "Foundations of inference"
author: ""
date: ""
output: html_document
editor_options: 
  chunk_output_type: console
---


## Main ideas

- Understand statistical process terminology

- Understand the types of conclusions that can be made given the underlying
  statistical process
  
## Coming Up

- Problem Set 3 due on Thursday
- No lab this week! 

### Lecture Notes and Exercises

We will use the packages below:
  
```{r load-packages, message=FALSE}
library(tidyverse)
```

## The statistical process


Statistics is a process that converts data into useful information, whereby
practitioners

1. form a question of interest,

2. collect and summarize data,

3. and interpret the results.

## The population of interest

The **population** is the group we'd like to learn something about. For 
example:

- What is the prevalence of diabetes among **U.S. adults**, and has it changed
  over time? 
  
- Does the average amount of caffeine vary by vendor in **12 oz. cups of**
  **coffee at Duke coffee shops**?
  
- Is there a relationship between tumor type and five-year mortality among
  **breast cancer patients**?

The **research question of interest** is what we want to answer - often 
relating one or more numerical quantities or summary statistics.

If we had data from every unit in the population, we could just calculate what
we wanted and be done!

## Sampling from the population

Unfortunately, we (usually) have to settle with a **sample** from the
population.

Ideally, the sample is **representative**, allowing us to make conclusions 
that are .**generalizable** to the broader population of interest. 

In order to make a formal statistical statement about the broader population of interest when all we have is a sample, we need to use the tools of probability and statistical inference.


## Big picture

```{r echo=FALSE, fig.width=12}
set.seed(234)
pop <- tibble(
  x = rnorm(1000, sd = 10),
  y = rnorm(1000),
  s = sample(rep(c(0, 1), times = c(950, 50)), size = 1000)
)
p1 <- ggplot(pop, aes(x = x, y = y)) +
  geom_point(color = "blue", size = 2, alpha = .5) +
  labs(title = "Population of interest", x = "", y = "") +
  theme_void()
p_arrow <- ggplot() +
  annotate(geom = "segment", x = 0, xend = 4, y = 0, 
           yend = 0, color = "black",
           size = 1, arrow = arrow()) +
  theme_void()
p2 <- ggplot(pop, aes(x = x, y = y, alpha = factor(s))) +
  geom_point(color = "red", size = 2) +
  scale_alpha_manual(values = c(0, 1)) +
  labs(title = "Sample", x = "", y = "") +
  theme_void() +
  theme(legend.position = "none")
(p1 | p_arrow | p2) 
```

We'll discuss a few population characteristics we'll be interested in.


## Explanatory and response variables

When we suspect one variable might causally affect another, we label the first variable the **explanatory variable** and the second the 
**response variable** Sometimes, you may also hear the term "independent variable" used instead of explanatory variable and "dependent variable" used instead of response variable.Whether or not we can actually make a causal 
connection will depend on the type of statistical study (more on this shortly).

<br/>

$$\mbox{Explanatory Variable} \longrightarrow \mbox{Response Variable}$$

<br/>

Do larger homes in good locations lead to higher home selling prices? What
are the explanatory and response variables?


## Population, parameter; sample, statistic

**Population**: a group of individuals or objects we are interested in 
studying

**Parameter**: a numerical quantity derived from the population
(almost always unknown)

  - Associate the parameter with the population

  - Parameters could be the mean, median, correlation, maximum, etc.

If we had data from every unit in the population, we could just calculate 
population parameters and be done! **Unfortunately, we usually cannot do this.**

**Sample**: a subset of our population of interest

**Statistic**: a numerical quantity derived from a sample:
  - Associate the statistic with the sample

  - Statistics could be the mean, median, correlation, maximum, etc.
  

Naturally, it makes sense to use the sample mean (and other quantities 
derived from the sample) to make generalizations about the population mean.


## Statistical inference

**Statistical inference** is the process of using sample data to make 
  conclusions about the underlying population the sample came from.

- **Estimation**: estimating an unknown parameter based on values from the
  sample at hand

- **Testing**: evaluating whether our observed sample provides evidence 
  for or against some claim about the population
  
In the coming lectures we'll discuss each of these inference approaches.

Before we get into this, let's discuss ways samples can be obtained and
what type of conclusions we'll be be able to make and **not** make as a result
of our statistical process.

# Sampling 

## Sampling strategies

- In our discussions on probability, we considered randomly selecting
  individuals from studies, where each individual was equally likely to be
  selected. This form of random sampling is known as **simple random         sampling.**
  
- **Stratified sampling** divides the population into **strata** such
  that each strata is homogenous. Then a simple random sample is applied within each stratum.
  - Can you think of a reason why we would employ this technique?

- **Cluster sampling** first partitions the population into **clusters**, where each cluster is representative of the population. A fixed number of clusters is selected and all observations within the cluster
  are included in the sample.
  
- **Multistage sampling** is similar to cluster sampling, but rather than
  keep all observations in each cluster, only a random sample of observations
  is kept.

## Example

Suppose we are interested in estimating the malaria rate in a densely tropical portion of rural Indonesia. We learn that there are 30 villages in that part 
of the Indonesian jungle, each more or less similar to the next. Our goal is to test 150 individuals for malaria. What are the costs and benefits to using
the four aforementioned sampling techniques?

- Simple random sample: expensive, may not get good representation from all
  30 villages
  
- Stratified sample: not clear how to build strata on an individual basis. 
  If strata are the villages, then some villages will be left out.
  
- Cluster sample / multistage: these are the best options here.

## Sample bias

- The four sampling strategies help reduce **bias** in our sample. A biased
  sample can lead to erroneous conclusions.
  
- Bias can still appear if the non-response rate is very high. 
    - Is our sample representative of the population or is it representative of 
      the population that "responded" to the survey?
  
```{r echo=FALSE, fig.width=12, fig.height=5}
set.seed(234)
pop <- tibble(
  x = rnorm(1000, sd = 10),
  y = rnorm(1000),
  r = sample(rep(c(0, 1), times = c(700, 300)), size = 1000),
  s = sample(rep(c(0, 1), times = c(950, 50)), size = 1000)
)
p1 <- ggplot(pop, aes(x = x, y = y)) +
  geom_point(color = "blue", size = 2, alpha = .5) +
  labs(title = "Population of interest", x = "", y = "") +
  theme_void()
p2 <- ggplot(pop, aes(x = x, y = y, alpha = factor(r))) +
  geom_point(color = "blue", size = 2) +
  scale_alpha_manual(values = c(0, .5)) +
  labs(title = "Population actually sampled", x = "", y = "") +
  theme_void() +
  theme(legend.position = "none")
p_arrow <- ggplot() +
  annotate(geom = "segment", x = 0, xend = 1, y = 0, 
           yend = 0, color = "black",
           size = 1, arrow = arrow()) +
  theme_void() +
  theme(plot.margin = unit(c(0, 0, 0, 0), "null"))
p3 <- ggplot(pop, aes(x = x, y = y, alpha = factor(s))) +
  geom_point(color = "red", size = 2) +
  scale_alpha_manual(values = c(0, 1)) +
  labs(title = "Sample", x = "", y = "") +
  theme_void() +
  theme(legend.position = "none")
(p1 | p_arrow | p2 | p_arrow | p3)
```


# Statistical studies and conclusions


## Observational studies and experiments

- Observational

    - Collect data in a way that does not interfere with how the data arise 
      ("observe")
    - Only establish an **association**
    - Data often cheaper and easier to collect

- Experimental

    - Randomly assign subjects to treatments
    - Establish **causal connections**
    - Often more expensive
    - Sometimes it is impossible or unethical to design an experiment

## Random sampling vs. random assignment

What do you think Pfizer did in their trials for the COVID-19 vaccine 
development?

# Pitfalls

## "Lucky coincidences"

-Check out the [spurious correlations](https://www.tylervigen.com/spurious-correlations) website. (Content warning: death/suicide examples.)

## Confounding variables

A **confounding** variable is an an extraneous variable that affects both 
the explanatory and the response variable, and makes it seem like there is 
a relationship between them.

Identify the confounding variable in each of the following statements:

1. As the amount of ice cream sales increases, the number of shark 
   attacks also increases.

2. The higher the number of firefighters at a fire is, the greater the amount 
   of damage caused by that fire.

3. Taller children are better at both reading and math compared to shorter 
   children.
   

One method to justify making causal conclusions from observational studies is 
to exhaust the search for confounding variables, there is no guarantee that all confounding variables can be examined or measured. Therefore, it is best
to only discuss associations between variables from observational studies.

# Practice:

## Polls and statistical terminology

Go to the Monmouth University Polling Institute 
[website](https://www.monmouth.edu/polling-institute/reports/) and select a 
poll of interest. Briefly read the poll results and methodology section at the
end. Try and identify the following:

- Population of interest:

- Parameter of interest:

- Sample:

- Sample size:

- Sample statistic:

- Sample statistic's value:

Link to poll:


# Confounding variables

A group of researchers decide to study the causes of heart disease by carrying 
out an observational study. The researchers find that the people in their 
study who ate lots of red meat also developed heart disease. They believe they 
have found a link (or ‘correlation’) between eating red meat and developing 
heart disease, and they (or those reading their research) might be tempted to 
conclude that eating lots of red meat is a cause of heart disease. However, 
before making a conclusion like this, the researchers must think about 
confounding factors (variables).

List three confounding factors that could be at play here.

1.

2. 

3.

Given that the above study was observational, what type of conclusion can be
made?

# References

1. https://www.understandinghealthresearch.org/useful-information/confounders-17